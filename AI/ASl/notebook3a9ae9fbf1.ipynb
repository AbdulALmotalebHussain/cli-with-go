{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-25T18:35:33.516921Z","iopub.status.busy":"2024-03-25T18:35:33.516428Z","iopub.status.idle":"2024-03-25T18:47:14.806266Z","shell.execute_reply":"2024-03-25T18:47:14.804971Z","shell.execute_reply.started":"2024-03-25T18:35:33.516868Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-03-28 20:24:27.509255: I tensorflow/core/platform/cpu_feature_guard.cc:181] Beginning TensorFlow 2.15, this package will be updated to install stock TensorFlow 2.15 alongside Intel's TensorFlow CPU extension plugin, which provides all the optimizations available in the package and more. If a compatible version of stock TensorFlow is present, only the extension will get installed. No changes to code or installation setup is needed as a result of this change.\n","More information on Intel's optimizations for TensorFlow, delivered as TensorFlow extension plugin can be viewed at https://github.com/intel/intel-extension-for-tensorflow.\n","2024-03-28 20:24:27.509334: I tensorflow/core/platform/cpu_feature_guard.cc:192] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_7113/2054702986.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Separate features and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Import necessary libraries\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Load the dataset\n","# Adjust the path according to your Kaggle dataset location\n","train_data = pd.read_csv('/home/snorpiii/pro/AI/ASl/archive/sign_mnist_train/sign_mnist_train.csv')\n","test_data = pd.read_csv('/home/snorpiii/pro/AI/ASl/archive/sign_mnist_test/sign_mnist_test.csv')\n","\n","# Separate features and labels\n","X_train = train_data.drop('label', axis=1).values.reshape(train_data.shape[0], 28, 28, 1).astype('float32')\n","X_test = test_data.drop('label', axis=1).values.reshape(test_data.shape[0], 28, 28, 1).astype('float32')\n","y_train = train_data['label'].values\n","y_test = test_data['label'].values\n","\n","# Normalize the data\n","X_train /= 255\n","X_test /= 255\n","\n","# One-hot encode labels\n","y_train = to_categorical(y_train, num_classes=26)\n","y_test = to_categorical(y_test, num_classes=26)\n","\n","# Define the model\n","model = Sequential([\n","    Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n","    MaxPooling2D(2, 2),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D(2, 2),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(26, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Data augmentation\n","datagen = ImageDataGenerator(\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=False\n",")\n","\n","# Train the model\n","model.fit(datagen.flow(X_train, y_train, batch_size=32),\n","          epochs=20,\n","          validation_data=(X_test, y_test),\n","          verbose=2)\n","\n","# Evaluate the model\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T18:47:14.809105Z","iopub.status.busy":"2024-03-25T18:47:14.808348Z","iopub.status.idle":"2024-03-25T18:47:14.865439Z","shell.execute_reply":"2024-03-25T18:47:14.863980Z","shell.execute_reply.started":"2024-03-25T18:47:14.809068Z"},"trusted":true},"outputs":[],"source":["# Import necessary libraries\n","import numpy as np\n","import cv2\n","import tensorflow as tf\n","\n","\n","# Define the alphabet mapping here\n","# Ensure this matches the classes your model was trained on\n","alphabet = 'abcdefghijklmnopqrstuvwxyz'  # Add or remove letters depending on your model\n","\n","# Start the webcam capture\n","cap = cv2.VideoCapture(0)\n","\n","while True:\n","    # Capture frame-by-frame\n","    ret, frame = cap.read()\n","    if not ret:\n","        print(\"Failed to grab frame\")\n","        break\n","    \n","    # Define the region of interest (ROI) coordinates\n","    x, y, w, h = 100, 100, 200, 200\n","    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n","    \n","    # Extract the ROI from the frame\n","    roi = frame[y:y+h, x:x+w]\n","    \n","    # Preprocess the ROI for prediction\n","    roi_resized = cv2.resize(roi, (28, 28))  # Resize to model's expected input size\n","    roi_gray = cv2.cvtColor(roi_resized, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n","    roi_normalized = roi_gray / 255.0  # Normalize pixel values\n","    roi_reshaped = np.expand_dims(roi_normalized, axis=[0, -1])  # Reshape to model's input shape\n","    \n","    # Perform the prediction\n","    prediction = model.predict(roi_reshaped)\n","    predicted_index = np.argmax(prediction)\n","    predicted_letter = alphabet[predicted_index]\n","    \n","    # Draw the predicted letter on the video frame\n","    cv2.putText(frame, predicted_letter, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n","\n","    # Display the resulting frame\n","    cv2.imshow('Sign Language Detection', frame)\n","    \n","    # Break the loop if 'q' key is pressed\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# When everything is done, release the capture\n","cap.release()\n","cv2.destroyAllWindows()\n","\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3258,"sourceId":5337,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
